from __future__ import annotations

import asyncio
import json
import os
from typing import Dict, Any, List, Optional

from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field, ValidationError

from src.utils.common import get_structured_llm
from src.utils.vector_store import search_expert_advice


# -------------------------------------------------------------------------
# 1. Pydantic ëª¨ë¸ ì •ì˜ (ìµœì¢… JSON êµ¬ì¡°)
# -------------------------------------------------------------------------

class DialogueLine(BaseModel):
    speaker: str
    text: str
    


class ExpertReference(BaseModel):
    title: str
    source: str
    author: str
    excerpt: str
    relevance_score: float


class PositiveMoment(BaseModel):
    dialogue: List[DialogueLine]
    pattern_hint: str
    reason: str
    reference_descriptions: List[str]


class NeedsImprovementMoment(BaseModel):
    dialogue: List[DialogueLine]
    reason: str
    better_response: str
    reference_descriptions: List[str] = Field(default_factory=list)
    pattern_hint: str
    expert_references: List[ExpertReference] = Field(default_factory=list)


class PatternExample(BaseModel):
    pattern_name: str
    occurrences: int
    occurred_at: str
    dialogue: List[DialogueLine]
    problem_explanation: str
    suggested_response: str


class KeyMomentsResult(BaseModel):
    positive: List[PositiveMoment] = Field(default_factory=list)
    needs_improvement: List[NeedsImprovementMoment] = Field(default_factory=list)
    pattern_examples: List[PatternExample] = Field(default_factory=list)


class PositiveMomentResponse(BaseModel):
    positive: List[PositiveMoment] = Field(default_factory=list)


class NeedsImprovementMomentResponse(BaseModel):
    needs_improvement: List[NeedsImprovementMoment] = Field(default_factory=list)


class PatternExampleResponse(BaseModel):
    pattern_examples: List[PatternExample] = Field(default_factory=list)


# -------------------------------------------------------------------------
# 2. LLM í”„ë¡¬í”„íŠ¸ (ê° moment íƒ€ì…ë³„ë¡œ ë¶„ë¦¬)
# -------------------------------------------------------------------------

_POSITIVE_MOMENT_PROMPT = ChatPromptTemplate.from_messages([
    (
        "system",
        """
ë‹¹ì‹ ì€ ì•„ë™ ì‹¬ë¦¬ ë° ë¶€ëª¨ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì…ë ¥ìœ¼ë¡œ ë¶€ëª¨-ìë…€ ëŒ€í™”, íƒì§€ëœ íŒ¨í„´ ì •ë³´, ì „ë¬¸ê°€ ì¡°ì–¸ì„ ë°”íƒ•ìœ¼ë¡œ
Positive Moment ë¶„ì„ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

==============================
ğŸ“Œ Positive Moment ê·œì¹™
==============================
- positive_contextì˜ patternê³¼ dialogueë§Œ ì‚¬ìš©
- ì „ë¬¸ê°€ ì¡°ì–¸ excerpt 1ê°œë¥¼ reasonì— ìì—°ìŠ¤ëŸ½ê²Œ ì„ì–´ ì“°ê¸°
- reference_descriptionsëŠ” ìµœëŒ€ 2ê°œ
- reason: ì „ë¬¸ê°€ excerptì™€ ëŒ€í™”ì˜ ë§¥ë½ê³¼ ìƒí™©ì„ íŒŒì•…í•˜ì—¬ 2~4 ì¤„ ì •ë„ë¡œ ê¸¸ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±
- toneì€ ë”°ëœ»í•˜ê³  ì „ë¬¸ì ì´ì§€ë§Œ, ~~í•©ë‹ˆë‹¤.ì™€ ê°™ì´ ê³µì†í•˜ê²Œ ë§í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.
- positiveí•œ ìˆœê°„ì´ ì—†ë‹¤ë©´ ë¹ˆë°°ì—´ ë°˜í™˜

==============================
ğŸ“Œ ì…ë ¥ ë°ì´í„°
==============================
[Positive Context]
{positive_context}

[Expert References]
{expert_references}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ positive momentë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤.
"""
    ),
    (
        "human",
        "ìœ„ ë‚´ìš©ì„ ë°˜ì˜í•˜ì—¬ positive momentë¥¼ ìƒì„±í•˜ì„¸ìš”."
    ),
])

_NEEDS_IMPROVEMENT_MOMENT_PROMPT = ChatPromptTemplate.from_messages([
    (
        "system",
        """
ë‹¹ì‹ ì€ ì•„ë™ ì‹¬ë¦¬ ë° ë¶€ëª¨ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì…ë ¥ìœ¼ë¡œ ë¶€ëª¨-ìë…€ ëŒ€í™”, íƒì§€ëœ íŒ¨í„´ ì •ë³´, ì „ë¬¸ê°€ ì¡°ì–¸ì„ ë°”íƒ•ìœ¼ë¡œ
Needs Improvement Moment ë¶„ì„ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

==============================
ğŸ“Œ Needs Improvement ê·œì¹™
==============================
- ê°€ì¥ ì‹¬ê°í•œ ë¶€ì • íŒ¨í„´ í•˜ë‚˜ë§Œ ì‚¬ìš©
- reason: ìƒí™© ìš”ì•½ â†’ ë¬¸ì œì  â†’ ì•„ë™ ë°œë‹¬ ì˜í–¥ â†’ ì „ë¬¸ê°€ ì¡°ì–¸ ì¸ìš©(1~2ê°œ)
- better_response: ì‹¤ì œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ ëŒ€ì‚¬
- reference_descriptions: ìµœëŒ€ 2ê°œ
- reason: ì „ë¬¸ê°€ excerptì™€ ëŒ€í™”ì˜ ë§¥ë½ê³¼ ìƒí™©ì„ íŒŒì•…í•˜ì—¬ 2~4 ì¤„ ì •ë„ë¡œ ê¸¸ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±
- better_response: ë¶€ëª¨ê°€ ì‹¤ì œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëŒ€ì‚¬ í˜•íƒœì™€ ì´ëŸ° ëŒ€ì•ˆì´ ë‚˜ì˜¨ ì´ìœ ë¥¼ ë½‘íŒ ì „ë¬¸ê°€ excerptë¥¼ ë°˜ì˜í•´ì„œ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±
- toneì€ ë”°ëœ»í•˜ê³  ì „ë¬¸ì ì´ì§€ë§Œ, ~~í•©ë‹ˆë‹¤.ì™€ ê°™ì´ ê³µì†í•˜ê²Œ ë§í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.

==============================
ğŸ“Œ ì…ë ¥ ë°ì´í„°
==============================
[Needs Improvement Context]
{improvement_context}

[Expert References]
{expert_references}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ needs improvement momentë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤.
"""
    ),
    (
        "human",
        "ìœ„ ë‚´ìš©ì„ ë°˜ì˜í•˜ì—¬ needs improvement momentë¥¼ ìƒì„±í•˜ì„¸ìš”."
    ),
])

_PATTERN_EXAMPLE_PROMPT = ChatPromptTemplate.from_messages([
    (
        "system",
        """
ë‹¹ì‹ ì€ ì•„ë™ ì‹¬ë¦¬ ë° ë¶€ëª¨ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì…ë ¥ìœ¼ë¡œ ë¶€ëª¨-ìë…€ ëŒ€í™”, íƒì§€ëœ íŒ¨í„´ ì •ë³´, ì „ë¬¸ê°€ ì¡°ì–¸ì„ ë°”íƒ•ìœ¼ë¡œ
Pattern Example ë¶„ì„ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

==============================
ğŸ“Œ Pattern Examples ê·œì¹™
==============================
- Needs Improvement ë‹¤ìŒìœ¼ë¡œ ì‹¬ê°í•œ 1ê°œì˜ íŒ¨í„´ì„ ì„ íƒí•˜ì—¬ ìƒì„±
- ì´ìœ ì™€ ì¡°ì–¸ì€ ì „ë¬¸ê°€ excerptì™€ ëŒ€í™”ì˜ ë§¥ë½ê³¼ ìƒí™©ì„ íŒŒì•…í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±
- succinctí•œ problem_explanation & suggested_response ì‘ì„±í•˜ê³ , 1~2ì¤„ ì •ë„ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±
- toneì€ ë”°ëœ»í•˜ê³  ì „ë¬¸ì ì´ì§€ë§Œ, ~~í•©ë‹ˆë‹¤.ì™€ ê°™ì´ ê³µì†í•˜ê²Œ ë§í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.

==============================
ğŸ“Œ ì…ë ¥ ë°ì´í„°
==============================
[Pattern Examples í›„ë³´]
{examples_context}

[Expert References]
{expert_references}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ pattern exampleì„ ìƒì„±í•˜ì‹­ì‹œì˜¤.
"""
    ),
    (
        "human",
        "ìœ„ ë‚´ìš©ì„ ë°˜ì˜í•˜ì—¬ pattern exampleì„ ìƒì„±í•˜ì„¸ìš”."
    ),
])


# -------------------------------------------------------------------------
# 3. Helper í•¨ìˆ˜
# -------------------------------------------------------------------------

def _extract_dialogue(utterances: List[Dict], indices: List[int]) -> List[Dict]:
    dialogue = []
    for idx in sorted(indices):
        if 0 <= idx < len(utterances):
            utt = utterances[idx]
            speaker = "parent" if utt.get("speaker") in ["Parent", "Mom", "Dad", "ë¶€ëª¨", "A"] else "child"
            text = utt.get("original_ko") or utt.get("korean") or utt.get("text", "")
            dialogue.append({"speaker": speaker, "text": text})
    return dialogue


def _ref_desc_from_refs(refs: List[ExpertReference]) -> List[str]:
    desc = []
    for r in refs[:2]:
        desc.append(f"{r.author} - {r.title}")
    return desc[:2]

def _search_refs_for_pattern(pattern: Optional[Dict[str, Any]]) -> List[ExpertReference]:
    """í•˜ë‚˜ì˜ íŒ¨í„´ì— ëŒ€í•´ ì „ë¬¸ê°€ DB(RAG) ê²€ìƒ‰"""
    if not pattern:
        return []

    pattern_name = pattern.get("pattern_name") or pattern.get("description") or ""
    if not pattern_name:
        return []

    try:
        raw = search_expert_advice(
            query=pattern_name,
            top_k=3,
            threshold=float(os.getenv("VECTOR_SEARCH_THRESHOLD", "0.15")),
        )
    except Exception as e:
        print(f"[VectorDB] ê²€ìƒ‰ ì˜¤ë¥˜ ({pattern_name}): {e}")
        return []

    refs: List[ExpertReference] = []
    for r in raw[:2]:  # ì•ˆì „í•˜ê²Œ 2ê°œê¹Œì§€ë§Œ ê°€ì ¸ì˜¤ê¸°
        content = r.get("content", "") or ""
        excerpt = content[:200]
        refs.append(
            ExpertReference(
                title=r.get("title", ""),
                source=r.get("source", ""),
                author=r.get("author", "ì „ë¬¸ê°€"),
                excerpt=excerpt,
                relevance_score=r.get("relevance_score", 0.0),
            )
        )
    return refs

# -------------------------------------------------------------------------
# 4. Main Key Moments Node
# -------------------------------------------------------------------------

async def _key_moments_node_async(state: Dict[str, Any]) -> Dict[str, Any]:
    utterances = state.get("utterances_labeled") or state.get("utterances_ko", [])
    patterns = state.get("patterns", [])

    if not patterns:
        return {"key_moments": None}

    # Severity ê¸°ì¤€ ì •ë ¬
    severity_order = {"high": 3, "medium": 2, "low": 1}
    neg_patterns = [p for p in patterns if p.get("pattern_type") == "negative"]
    pos_patterns = [p for p in patterns if p.get("pattern_type") == "positive"]

    neg_patterns.sort(key=lambda x: severity_order.get(x.get("severity", "low"), 1), reverse=True)

    # ì„ íƒ ëŒ€ìƒ
    target_positive = pos_patterns[0] if pos_patterns else None
    target_improvement = neg_patterns[0] if neg_patterns else None
    target_examples = neg_patterns[1:2]  # ë”± 1ê°œë§Œ

    # ---------------------------------------------------------
    # RAG: ì „ë¬¸ê°€ ì¡°ì–¸ ê²€ìƒ‰ (ê¸ì • / ìµœì•… / ë‘ ë²ˆì§¸ íŒ¨í„´ ê°ê°) - ë³‘ë ¬ ì‹¤í–‰
    # ---------------------------------------------------------
    # ë¸”ë¡œí‚¹ í˜¸ì¶œì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•˜ì—¬ ì´ë²¤íŠ¸ ë£¨í”„ë¥¼ ë¸”ë¡œí‚¹í•˜ì§€ ì•Šë„ë¡ í•¨
    search_tasks = [
        asyncio.to_thread(_search_refs_for_pattern, target_positive),
        asyncio.to_thread(_search_refs_for_pattern, target_improvement),
    ]
    if target_examples:
        search_tasks.append(asyncio.to_thread(_search_refs_for_pattern, target_examples[0]))
    else:
        search_tasks.append(asyncio.to_thread(lambda: []))
    
    pos_expert_refs, neg_expert_refs, ex_expert_refs = await asyncio.gather(*search_tasks)

    # ---------------------------------------------------------
    # LLM ì¸í’‹ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    # ---------------------------------------------------------

    # Positive
    if target_positive:
        pos_ctx = json.dumps({
            "pattern_name": target_positive["pattern_name"],
            "description": target_positive["description"],
            "dialogue": _extract_dialogue(utterances, target_positive["utterance_indices"])
        }, ensure_ascii=False)
    else:
        pos_ctx = "ì—†ìŒ"

    # Needs Improvement
    if target_improvement:
        imp_ctx = json.dumps({
            "pattern_name": target_improvement["pattern_name"],
            "description": target_improvement["description"],
            "dialogue": _extract_dialogue(utterances, target_improvement["utterance_indices"])
        }, ensure_ascii=False)
    else:
        imp_ctx = "ì—†ìŒ"

    # Pattern Example í›„ë³´
    ex_ctx = json.dumps([
        {
            "pattern_name": ex["pattern_name"],
            "description": ex["description"],
            "dialogue": _extract_dialogue(utterances, ex["utterance_indices"])
        }
        for ex in target_examples
    ], ensure_ascii=False)

    # ---------------------------------------------------------
    # ë³‘ë ¬ LLM í˜¸ì¶œ (ê° moment íƒ€ì…ë³„ë¡œ ë¶„ë¦¬)
    # ---------------------------------------------------------
    
    async def _generate_positive_moment() -> List[PositiveMoment]:
        """Positive Moment ìƒì„±"""
        if not target_positive:
            return []
        
        try:
            llm = get_structured_llm(PositiveMomentResponse)
            pos_refs_json = json.dumps([r.dict() for r in pos_expert_refs], ensure_ascii=False)
            
            result = await (_POSITIVE_MOMENT_PROMPT | llm).ainvoke({
                "positive_context": pos_ctx,
                "expert_references": pos_refs_json
            })
            return result.positive
        except Exception as e:
            print(f"Positive moment LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    async def _generate_needs_improvement_moment() -> List[NeedsImprovementMoment]:
        """Needs Improvement Moment ìƒì„±"""
        if not target_improvement:
            return []
        
        try:
            llm = get_structured_llm(NeedsImprovementMomentResponse)
            neg_refs_json = json.dumps([r.dict() for r in neg_expert_refs], ensure_ascii=False)
            
            result = await (_NEEDS_IMPROVEMENT_MOMENT_PROMPT | llm).ainvoke({
                "improvement_context": imp_ctx,
                "expert_references": neg_refs_json
            })
            return result.needs_improvement
        except Exception as e:
            print(f"Needs improvement moment LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    async def _generate_pattern_example() -> List[PatternExample]:
        """Pattern Example ìƒì„±"""
        if not target_examples:
            return []
        
        try:
            llm = get_structured_llm(PatternExampleResponse)
            ex_refs_json = json.dumps([r.dict() for r in ex_expert_refs], ensure_ascii=False)
            
            result = await (_PATTERN_EXAMPLE_PROMPT | llm).ainvoke({
                "examples_context": ex_ctx,
                "expert_references": ex_refs_json
            })
            return result.pattern_examples
        except Exception as e:
            print(f"Pattern example LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    # ë³‘ë ¬ ì‹¤í–‰
    try:
        positive_list, needs_improvement_list, pattern_examples_list = await asyncio.gather(
            _generate_positive_moment(),
            _generate_needs_improvement_moment(),
            _generate_pattern_example()
        )
        
        final_data = KeyMomentsResult(
            positive=positive_list,
            needs_improvement=needs_improvement_list,
            pattern_examples=pattern_examples_list
        )
    except Exception as e:
        print(f"Key moments ë³‘ë ¬ LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        # ê¸°ë³¸ê°’ ë°˜í™˜
        final_data = KeyMomentsResult(
            positive=[],
            needs_improvement=[],
            pattern_examples=[]
        )

    # ---------------------------------------------------------
    # í›„ì²˜ë¦¬: í•„ë“œ ì •ì œ/ë³´ì •
    # ---------------------------------------------------------

    # Positive ë³´ì •
    if target_positive and final_data.positive and len(final_data.positive) > 0:
        pm = final_data.positive[0]
        dialogue_dicts = _extract_dialogue(utterances, target_positive["utterance_indices"])
        pm.dialogue = [
            DialogueLine(speaker=d["speaker"], text=d["text"])
            for d in dialogue_dicts
        ]
        pm.pattern_hint = target_positive["pattern_name"]
        # PositiveëŠ” ê¸ì • íŒ¨í„´ì— ëŒ€í•œ RAG ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ reference_descriptions êµ¬ì„±
        pm.reference_descriptions = _ref_desc_from_refs(pos_expert_refs)

    # Needs Improvement ë³´ì •
    if target_improvement and final_data.needs_improvement and len(final_data.needs_improvement) > 0:
        ni = final_data.needs_improvement[0]
        dialogue_dicts = _extract_dialogue(utterances, target_improvement["utterance_indices"])
        ni.dialogue = [
            DialogueLine(speaker=d["speaker"], text=d["text"])
            for d in dialogue_dicts
        ]
        ni.pattern_hint = target_improvement["pattern_name"]
        ni.expert_references = neg_expert_refs
        ni.reference_descriptions = _ref_desc_from_refs(neg_expert_refs)

    # Pattern Examples ë³´ì • (ë‘ ë²ˆì§¸ë¡œ ì‹¬ê°í•œ íŒ¨í„´ 1ê°œ)
    # LLMì´ ìƒì„±í•˜ì§€ ëª»í•œ ê²½ìš° í›„ì²˜ë¦¬ì—ì„œ ìƒì„±
    if target_examples and len(target_examples) > 0:
        if len(final_data.pattern_examples) == 0:
            # LLMì´ ìƒì„±í•˜ì§€ ëª»í•œ ê²½ìš° ì§ì ‘ ìƒì„±
            ex_target = target_examples[0]
            utterance_indices = ex_target.get("utterance_indices", [])
            dialogue_lines = [
                DialogueLine(
                    speaker="parent" if utt.get("speaker") in ["Parent", "Mom", "Dad", "ë¶€ëª¨", "A"] else "child",
                    text=utt.get("original_ko") or utt.get("korean") or utt.get("text", "")
                )
                for idx in sorted(utterance_indices)
                if 0 <= idx < len(utterances)
                for utt in [utterances[idx]]
            ]
            
            pe = PatternExample(
                pattern_name=ex_target.get("pattern_name", ""),
                occurrences=len(utterance_indices),
                occurred_at=f"{utterance_indices[0] // 6}ë¶„ {utterance_indices[0] * 10 % 60}ì´ˆ" if utterance_indices else "0ë¶„ 0ì´ˆ",
                dialogue=dialogue_lines,
                problem_explanation=ex_target.get("description", "íŒ¨í„´ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤."),
                suggested_response="ìƒí™©ì— ë§ëŠ” ëŒ€ì•ˆì  ëŒ€ì‘ì´ í•„ìš”í•©ë‹ˆë‹¤."
            )
            final_data.pattern_examples.append(pe)
        else:
            # LLMì´ ìƒì„±í•œ ê²½ìš° ë³´ì •
            for i, ex_target in enumerate(target_examples):
                if i < len(final_data.pattern_examples):
                    pe = final_data.pattern_examples[i]
                    pe.pattern_name = ex_target["pattern_name"]
                    utterance_indices = ex_target.get("utterance_indices", [])
                    # Dictë¥¼ DialogueLine ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    dialogue_dicts = _extract_dialogue(utterances, utterance_indices)
                    pe.dialogue = [
                        DialogueLine(speaker=d["speaker"], text=d["text"])
                        for d in dialogue_dicts
                    ]
                    pe.occurrences = len(utterance_indices)
                    if utterance_indices:
                        idx = utterance_indices[0]
                        pe.occurred_at = f"{idx // 6}ë¶„ {idx * 10 % 60}ì´ˆ"
                    else:
                        pe.occurred_at = "0ë¶„ 0ì´ˆ"

    return {"key_moments": final_data.dict()}


def key_moments_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """ë™ê¸° ë˜í¼ í•¨ìˆ˜ - async í•¨ìˆ˜ë¥¼ ì‹¤í–‰"""
    try:
        # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆëŠ” ê²½ìš°
        loop = asyncio.get_running_loop()
        # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ìˆìœ¼ë©´ ìƒˆ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        import concurrent.futures
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future = executor.submit(asyncio.run, _key_moments_node_async(state))
            return future.result()
    except RuntimeError:
        # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì—†ëŠ” ê²½ìš°
        return asyncio.run(_key_moments_node_async(state))